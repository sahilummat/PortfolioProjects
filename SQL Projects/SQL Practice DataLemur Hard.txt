***Active User Retention [Facebook SQL Interview Question]
https://datalemur.com/questions/user-retention

;with cte as (
SELECT user_id,COUNT(DISTINCT date_part('month',event_date)) as monthly_active_users
,MAX(date_part('month',event_date)) as mth
FROM user_actions
where event_date >='06/01/2022' and event_date<='07/31/2022'
group by user_id)
select mth,count(*) from cte 
where monthly_active_users>=2
group by mth


***Y-on-Y Growth Rate [Wayfair SQL Interview Question]
https://datalemur.com/questions/yoy-growth-rate

with cte as (
SELECT 
date_part('year',transaction_date) as year,
product_id,spend as curr_year_spend
,lag(spend)over(partition by product_id order by date_part('year',transaction_date))
as prev_year_spend
FROM user_transactions)
select * ,
ROUND((curr_year_spend-prev_year_spend)*100.0/prev_year_spend,2) as yoy_rate
from cte 


***Maximize Prime Item Inventory [Amazon SQL Interview Question]
https://datalemur.com/questions/prime-warehouse-storage

with cte as (
SELECT item_type
,count(*) as batch_size,
SUM(square_footage) as area_per_item_type
FROM inventory
group by item_type)
,prime_item as ( 
select item_type,
area_per_item_type,
floor(500000/area_per_item_type) as prime_item_batch_count,
floor(500000/area_per_item_type)*batch_size as prime_item_count
from cte where item_type='prime_eligible')
,non_prime as (

select item_type,
area_per_item_type,
floor((500000-(select area_per_item_type *prime_item_batch_count from prime_item))/area_per_item_type) as non_prime_item_batch_count,
floor((500000-(select area_per_item_type *prime_item_batch_count from prime_item))/area_per_item_type)*batch_size as non_prime_item_count
from cte where item_type='not_prime'
)
select item_type,non_prime_item_count as item_count from (
select * from non_prime
union all 
select * from prime_item)a
order by item_count desc 


***Median Google Search Frequency [Google SQL Interview Question]
https://datalemur.com/questions/median-search-freq

with cte as (
SELECT searches
  FROM search_frequency
  GROUP BY 
    searches,GENERATE_SERIES(1, num_users))
    
    select ROUND(PERCENTILE_CONT(.50) WITHIN GROUP (order by searches ):: decimal,1)
    as median
    from cte 
 
***Advertiser Status [Facebook SQL Interview Question]
https://datalemur.com/questions/updated-status

with cte as (
SELECT COALESCE(a.user_id,dp.user_id) as user_id,a.status
,dp.paid as payment
from 
advertiser  a  
full outer join daily_pay dp on a.user_id=dp.user_id)
,cte2 as (
select *,
case when payment is null then 'Not Paid' else 'Paid' end as paymentt
from cte )
select user_id,new_status from (
select *,
case when paymentt ='Not Paid' then 'CHURN' 
      when paymentt='Paid' and status='CHURN' then 'RESURRECT'
      when status is null then 'NEW'
      else 'EXISTING'
 end as new_status
from cte2)a
order by a.user_id



***Consecutive Filing Years [Intuit SQL Interview Question]
https://datalemur.com/questions/consecutive-filing-years

with cte as (
select * from filed_taxes
where user_id in (
select user_id
from filed_taxes
group by user_id having count(1)>=3
)
),final as (
select *,
lag(product) over (partition by user_id order by filing_date) as prev_prod,
lead(product) over (partition by user_id order by filing_date) as next_prod
from cte )
select  DISTINCT user_id from (
select *,
Case when left(product,8)=left(prev_prod,8) and left(product,8)=left(next_prod,8) then 1 else 0 end as flag
from final)a where a.flag=1


***Marketing Touch Streak [Snowflake SQL Interview Question]
https://datalemur.com/questions/marketing-touch-streak

;with cte as (
select *
from marketing_touches 
where contact_id in 
(select contact_id from marketing_touches group by contact_id HAVING
count(1)>=3)
),final as (
select *, date_trunc('week',event_date) as start_of_week
from cte 
where contact_id IN
(select DISTINCT contact_id from cte where event_type='trial_request'))
,final2 as (
select *,
lead(start_of_week,1)over(PARTITION BY contact_id order by start_of_week) as next_week,
lag(start_of_week,1)over(PARTITION BY contact_id order by start_of_week) as prev_week
from final)
select cc.email as email
from final2 ff
inner join crm_contacts cc on ff.contact_id=cc.contact_id
where 
DATE_PART('week', start_of_week::date)-DATE_PART('week', prev_week::date)=1
and 
DATE_PART('week', next_week::date)-DATE_PART('week', start_of_week::date)=1


***3-Topping Pizzas [McKinsey SQL Interview Question]
https://datalemur.com/questions/pizzas-topping-cost

;with master as (
SELECT *
FROM pizza_toppings)

select 
m1.topping_name || ',' || m2.topping_name||','|| m3.topping_name as pizza,
m1.ingredient_cost+m2.ingredient_cost+m3.ingredient_cost as total_cost
from master m1 inner join master m2 on m1.topping_name < m2.topping_name
inner join master m3 on m2.topping_name < m3.topping_name
order by total_cost desc,pizza


***Compressed Median [Alibaba SQL Interview Question]
https://datalemur.com/questions/alibaba-compressed-median

WITH summary AS (
SELECT item_count
FROM items_per_order
GROUP BY
  item_count,
  GENERATE_SERIES(1, order_occurrences)
)

SELECT 
  ROUND(
    PERCENTILE_CONT(0.50) WITHIN GROUP (
    ORDER BY item_count)::DECIMAL, 1) AS median
FROM summary;

***Average Vacant Days [Airbnb SQL Interview Question]
https://datalemur.com/questions/average-vacant-days

;with cte as (
select l.listing_id as lid,b.*,
case when checkin_date < '1/1/2021 00:00:00' then '1/1/2021 00:00:00' 
else  checkin_date end as correct_checkin,
case when checkout_date > '12/31/2021 00:00:00' then '12/31/2021 00:00:00' 
else  checkout_date end as correct_checkout
from listings l
LEFT JOIN bookings b on l.listing_id=b.listing_id 
where  l.is_active=1)
,final as (
select lid, cast((correct_checkout-correct_checkin)as int) as number_of_days
from cte)
select ROUND(SUM(total_vacant_days)*1.0/COUNT(DISTINCT lid) ) as avg_vacant_days
from (
select lid,365-COALESCE(SUM(number_of_days),0) as total_vacant_days
from final
group by lid
)a


***Patient Support Analysis (Part 3) [UnitedHealth SQL Interview Question]
https://datalemur.com/questions/patient-call-history

WITH call_history AS (
  SELECT
    policy_holder_id,
    call_date AS current_call, -- Remove this column
    LAG(call_date) OVER (
  	  PARTITION BY policy_holder_id ORDER BY call_date) AS previous_call, -- Remove this column
    ROUND(EXTRACT(EPOCH FROM call_date 
      - LAG(call_date) OVER (
  	    PARTITION BY policy_holder_id ORDER BY call_date)
    )/(24*60*60),2) AS time_diff_days
  FROM callers
)
SELECT COUNT(DISTINCT policy_holder_id) AS policy_holder_count
FROM call_history
WHERE time_diff_days <= 7;


***Patient Support Analysis (Part 4) [UnitedHealth SQL Interview Question]
https://datalemur.com/questions/long-calls-growth

;with cte as (
select EXTRACT(year from call_date) as yr,
EXTRACT(month from call_date) as mnth,
count(case_id) as call_duration_secs,
lag(count(case_id))OVER
(order by EXTRACT(year from call_date),EXTRACT(month from call_date)) as prev_month_duration
from callers 
where call_duration_secs >=300
group by yr,mnth)
select yr,mnth as mth,
ROUND((call_duration_secs-prev_month_duration)*100.0/prev_month_duration,1) as long_calls_growth_pct
from cte 


***Same Week Purchases [Etsy SQL Interview Question]
https://datalemur.com/questions/same-week-purchases

;with cte as (
select s.user_id,s.signup_date,a.purchase_date
from signups s
left join (
select *
,row_number()over(PARTITION BY  user_id order by purchase_date) as rn 
from user_purchases )a on s.user_id=a.user_id and a.rn=1)
select ROUND(SUM(number_of_days)*100.0/count(1),2) as single_purchase_pct
from (
select *,
case when 
EXTRACT(EPOCH FROM (purchase_date - signup_date))/(24*60*60) <=7 then 1 else 0 END
as number_of_days
from cte )a


***Follow-Up Airpod Percentage [Apple SQL Interview Question]
https://datalemur.com/questions/follow-up-airpod-percentage

;with cte as (
select *,
lag(product_name)over(PARTITION BY customer_id order by transaction_id)
as prev_item_bought,
case 
when product_name='AirPods' and 
lag(product_name)over(PARTITION BY customer_id order by transaction_id)='iPhone'
then 1 else 0 end as flag
from transactions )
select ROUND(SUM(flag)*100.0/count(DISTINCT customer_id)) as round
from cte 
